"""
Feature engineering for parking prediction
"""
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from config import ZONE_TYPE_ENCODING, ZONE_METADATA


def extract_temporal_features(dt):
    """Extract time-based features from datetime"""
    return {
        'hour': dt.hour,
        'day_of_week': dt.weekday(),  # 0=Monday, 6=Sunday
        'is_weekend': 1 if dt.weekday() >= 5 else 0,
        'month': dt.month,
        'is_rush_hour': 1 if dt.hour in [7, 8, 17, 18] else 0
    }


def get_historical_features(zone_id, target_dt, historical_df):
    """
    Calculate historical patterns for this zone/time
    
    Args:
        zone_id: Zone identifier
        target_dt: Target datetime
        historical_df: Historical parking data
    
    Returns:
        dict with historical features
    """
    # Ensure target_dt is a datetime object, not a Series
    if hasattr(target_dt, 'weekday'):
        # It's a datetime-like object
        target_weekday = target_dt.weekday() if callable(target_dt.weekday) else target_dt.weekday
        target_hour = target_dt.hour
    else:
        # Fallback
        target_weekday = 0
        target_hour = 12
    
    # Filter to same zone, hour, and day of week
    same_pattern = historical_df[
        (historical_df['blockface_id'] == zone_id) &
        (historical_df['datetime'].dt.hour == target_hour) &
        (historical_df['datetime'].dt.weekday == target_weekday)
    ]
    
    if len(same_pattern) > 0:
        avg_same_hour = same_pattern['occupancy_rate'].mean()
        std_same_hour = same_pattern['occupancy_rate'].std()
    else:
        # Fallback to overall average
        zone_data = historical_df[historical_df['blockface_id'] == zone_id]
        avg_same_hour = zone_data['occupancy_rate'].mean() if len(zone_data) > 0 else 0.5
        std_same_hour = 0.15
    
    # Calculate 24h trend
    recent_data = historical_df[
        (historical_df['blockface_id'] == zone_id) &
        (historical_df['datetime'] >= target_dt - timedelta(hours=24)) &
        (historical_df['datetime'] < target_dt)
    ].sort_values('datetime')
    
    if len(recent_data) >= 2:
        trend_24h = recent_data['occupancy_rate'].iloc[-1] - recent_data['occupancy_rate'].iloc[0]
    else:
        trend_24h = 0.0
    
    return {
        'avg_same_hour': avg_same_hour,
        'std_same_hour': std_same_hour,
        'trend_24h': trend_24h
    }


def get_lag_features(zone_id, target_dt, historical_df):
    """
    Get occupancy at previous time points (lag features)
    
    Args:
        zone_id: Zone identifier
        target_dt: Target datetime
        historical_df: Historical parking data
    
    Returns:
        dict with lag features
    """
    def get_occupancy_at(dt):
        """Helper to get occupancy at specific datetime"""
        data = historical_df[
            (historical_df['blockface_id'] == zone_id) &
            (historical_df['datetime'] >= dt - timedelta(minutes=30)) &
            (historical_df['datetime'] <= dt + timedelta(minutes=30))
        ]
        if len(data) > 0:
            return data['occupancy_rate'].mean()
        return 0.5  # Default fallback
    
    return {
        'occupancy_1h_ago': get_occupancy_at(target_dt - timedelta(hours=1)),
        'occupancy_24h_ago': get_occupancy_at(target_dt - timedelta(hours=24)),
        'occupancy_7d_ago': get_occupancy_at(target_dt - timedelta(days=7))
    }


def get_event_features(zone_id, target_dt, events_df):
    """
    Check for nearby events
    
    Args:
        zone_id: Zone identifier
        target_dt: Target datetime
        events_df: Events dataframe
    
    Returns:
        dict with event features
    """
    if len(events_df) == 0:
        return {
            'has_event': 0,
            'hours_until_event': 99
        }
    
    # Check if this zone is affected by any event
    # Filter events where zone_id is in the nearby_zones list
    nearby_events = []
    for idx, row in events_df.iterrows():
        nearby_zones = row['nearby_zones']
        # Convert to list if it's a string (shouldn't happen but defensive)
        if isinstance(nearby_zones, str):
            # Try to parse as JSON array
            import json
            try:
                nearby_zones = json.loads(nearby_zones.replace("'", '"'))
            except:
                nearby_zones = []
        
        # Check if zone is in the list
        if isinstance(nearby_zones, list) and zone_id in nearby_zones:
            nearby_events.append(row)
    
    if len(nearby_events) == 0:
        return {
            'has_event': 0,
            'hours_until_event': 99
        }
    
    # Convert to DataFrame for easier processing
    nearby_events_df = pd.DataFrame(nearby_events)
    
    # Find events on the same day
    target_date = target_dt.date()
    today_events = nearby_events_df[
        pd.to_datetime(nearby_events_df['date']).dt.date == target_date
    ]
    
    if len(today_events) > 0:
        # Get the closest event
        event = today_events.iloc[0]
        event_datetime = pd.to_datetime(f"{event['date']} {event['start_time']}")
        hours_until = (event_datetime - target_dt).total_seconds() / 3600
        
        return {
            'has_event': 1,
            'hours_until_event': hours_until
        }
    
    return {
        'has_event': 0,
        'hours_until_event': 99  # Large number = no event
    }


def get_zone_features(zone_id):
    """
    Get static zone features
    
    Args:
        zone_id: Zone identifier
    
    Returns:
        dict with zone features
    """
    metadata = ZONE_METADATA.get(zone_id, {})
    zone_type = metadata.get('type', 'commercial')
    
    return {
        'zone_type_encoded': ZONE_TYPE_ENCODING.get(zone_type, 0),
        'total_capacity': metadata.get('capacity', 20)
    }


def extract_all_features(zone_id, target_dt, historical_df, events_df):
    """
    Extract all 15 features for a prediction
    
    Args:
        zone_id: Zone identifier
        target_dt: Target datetime to predict
        historical_df: Historical parking data
        events_df: Events dataframe
    
    Returns:
        list of 15 feature values in correct order
    """
    features = {}
    
    # Temporal (5 features)
    features.update(extract_temporal_features(target_dt))
    
    # Historical (3 features)
    features.update(get_historical_features(zone_id, target_dt, historical_df))
    
    # Lag (3 features)
    features.update(get_lag_features(zone_id, target_dt, historical_df))
    
    # Event (2 features)
    features.update(get_event_features(zone_id, target_dt, events_df))
    
    # Zone (2 features)
    features.update(get_zone_features(zone_id))
    
    # Return in correct order (matching FEATURE_NAMES in config)
    feature_order = [
        'hour', 'day_of_week', 'is_weekend', 'month', 'is_rush_hour',
        'avg_same_hour', 'std_same_hour', 'trend_24h',
        'occupancy_1h_ago', 'occupancy_24h_ago', 'occupancy_7d_ago',
        'has_event', 'hours_until_event',
        'zone_type_encoded', 'total_capacity'
    ]
    
    return [features[key] for key in feature_order]


def create_training_dataset(historical_df, events_df):
    """
    Create full training dataset with features and targets - IMPROVED VERSION
    
    Args:
        historical_df: Historical parking data
        events_df: Events dataframe
    
    Returns:
        X (features), y (targets)
    """
    print("Creating training dataset (SAFE & IMPROVED)...")
    print(f"Total records: {len(historical_df)}")
    
    # Make a copy to avoid modifying original
    df = historical_df.copy()
    
    # Pre-compute temporal features (vectorized - FAST!)
    print("Computing temporal features...")
    df['hour'] = df['datetime'].dt.hour
    df['day_of_week'] = df['datetime'].dt.dayofweek
    df['is_weekend'] = (df['datetime'].dt.dayofweek >= 5).astype(int)
    df['month'] = df['datetime'].dt.month
    df['is_rush_hour'] = df['hour'].isin([7, 8, 17, 18]).astype(int)
    
    # Pre-compute zone features (vectorized properly)
    print("Computing zone features...")
    # Create lookup dictionaries once
    zone_type_map = {zone_id: ZONE_TYPE_ENCODING.get(meta.get('type', 'commercial'), 0) 
                     for zone_id, meta in ZONE_METADATA.items()}
    zone_capacity_map = {zone_id: meta.get('capacity', 20) 
                         for zone_id, meta in ZONE_METADATA.items()}
    
    df['zone_type_encoded'] = df['blockface_id'].map(zone_type_map).fillna(0).astype(int)
    df['total_capacity'] = df['blockface_id'].map(zone_capacity_map).fillna(20).astype(int)
    
    # IMPROVED: Historical features grouped by zone + hour + day_of_week
    print("Computing historical averages (improved)...")
    zone_hour_day_avg = df.groupby(['blockface_id', 'hour', 'day_of_week'])['occupancy_rate'].agg(['mean', 'std']).reset_index()
    zone_hour_day_avg.columns = ['blockface_id', 'hour', 'day_of_week', 'avg_same_hour', 'std_same_hour']
    zone_hour_day_avg['std_same_hour'] = zone_hour_day_avg['std_same_hour'].fillna(0.15)
    
    df = df.merge(zone_hour_day_avg, on=['blockface_id', 'hour', 'day_of_week'], how='left')
    df['avg_same_hour'] = df['avg_same_hour'].fillna(0.5)
    df['std_same_hour'] = df['std_same_hour'].fillna(0.15)
    
    # SAFE: Lag features using zone averages (NO DATA LEAKAGE)
    # This is intentionally simplified to avoid overfitting
    print("Computing lag features (safe - using zone averages)...")
    zone_avg = df.groupby('blockface_id')['occupancy_rate'].mean()
    df['occupancy_1h_ago'] = df['blockface_id'].map(zone_avg)
    df['occupancy_24h_ago'] = df['blockface_id'].map(zone_avg)
    df['occupancy_7d_ago'] = df['blockface_id'].map(zone_avg)
    df['trend_24h'] = 0.0  # Simplified to avoid data leakage
    
    # Event features (vectorized)
    print("Computing event features...")
    df['has_event'] = 0
    df['hours_until_event'] = 99.0
    
    # For each event, mark affected zones
    for _, event in events_df.iterrows():
        event_date = pd.to_datetime(event['date'])
        event_time = pd.to_datetime(f"{event['date']} {event['start_time']}")
        nearby_zones = event['nearby_zones']
        
        # Find records on same day and in nearby zones
        mask = (
            (df['datetime'].dt.date == event_date.date()) &
            (df['blockface_id'].isin(nearby_zones))
        )
        
        if mask.any():
            df.loc[mask, 'has_event'] = 1
            # Calculate hours until event for these records
            hours_diff = (event_time - df.loc[mask, 'datetime']).dt.total_seconds() / 3600
            # Simple: just use the first event found (or could use min/max logic)
            df.loc[mask, 'hours_until_event'] = hours_diff
    
    # Extract features in correct order
    print("Assembling feature matrix...")
    feature_columns = [
        'hour', 'day_of_week', 'is_weekend', 'month', 'is_rush_hour',
        'avg_same_hour', 'std_same_hour', 'trend_24h',
        'occupancy_1h_ago', 'occupancy_24h_ago', 'occupancy_7d_ago',
        'has_event', 'hours_until_event',
        'zone_type_encoded', 'total_capacity'
    ]
    
    X = df[feature_columns].values
    y = df['occupancy_rate'].values
    
    print(f"âœ… Created {len(X)} training samples (safe, no data leakage)!")
    return X, y
